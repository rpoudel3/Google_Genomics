{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a bucket and adding files to a bucket from another bucket within google cloud storage\n",
    "\n",
    "1.On the home page, click on the products and services right next to where it says Google Cloud Platform.\n",
    "\n",
    "2.Select Storage,then click on Create buckets to create a bucket.\n",
    "\n",
    "3.Go to this link to get to Phase-1 1000 genome bucket \n",
    "\n",
    "https://console.cloud.google.com/storage/browser/genomics-public-data/1000-genomes/vcf/\n",
    "\n",
    "4.On the right hand corner of a file, click on the ? to copy the files to your bucket.\n",
    "\n",
    "5.On the destination put your bucket location to copy that file in the following format:\n",
    "\n",
    "bucket_1_640/upload_1/Copy of ALL.chrY.phase1_samtools_si.20101123.snps.low_coverage.genotypes.vcf\n",
    "\n",
    "7.Refresh on your bucket to see the changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources for published data\n",
    "\n",
    "http://googlegenomics.readthedocs.io/en/latest/use_cases/discover_public_data/index.html\n",
    "\n",
    "#### Transferring files from TCGA to Google Cloud Storage\n",
    "\n",
    "https://github.com/isb-cgc/ISB-CGC-data-proc\n",
    "\n",
    "This is one of the location for transferring files from tcga project to the google cloud storage\n",
    "\n",
    "https://bigquery.cloud.google.com/dataset/isb-cgc:tcga_201510_alpha\n",
    "\n",
    " \n",
    "\n",
    "#### Enabling the Google Cloud Platform API\n",
    "\n",
    "https://console.developers.google.com/apis/api/compute_component/overview?project=angelic-surfer-143303&pli=1\n",
    "\n",
    "Press enable\n",
    "\n",
    "Once that is done, go to Credentials\n",
    "\n",
    "640_Project- account name\n",
    "account ID-id-40-project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing SDK installer\n",
    "\n",
    "https://cloud.google.com/sdk/downloads\n",
    "\n",
    "This needs to be installed to use the tools and libraries in Google genomics,google compute engine, google cloud server and Bigquery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bioconductor Setup and Guidelines\n",
    "\n",
    "https://github.com/Bioconductor/GoogleGenomics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apache Spark Facts:\n",
    "    \n",
    "http://spark.apache.org/faq.html\n",
    "\n",
    "#### Spark Examples:\n",
    "https://github.com/googlegenomics/spark-examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Connecting to Spark and Hadoop\n",
    "\n",
    "Running the example cluster documentation:\n",
    "\n",
    "http://googlegenomics.readthedocs.io/en/latest/use_cases/compute_principal_coordinate_analysis/1-way-pca.html#id2\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Creating clusters ( step by step)\n",
    "\n",
    "Go the project, homepage and then create cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step by Step : \n",
    "## \"Compute Principal Coordinate Analysis\" tutorial  in Google Genomics: with updates\n",
    "http://googlegenomics.readthedocs.io/en/latest/use_cases/compute_principal_coordinate_analysis/1-way-pca.html"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Objective : Computing principal components from genetic data using Google cloud platform and Spark\n",
    "\n",
    "Tools used : \n",
    "    Google Cloud platform \n",
    "    Spark 2.0\n",
    "    Scala 2.11.8\n",
    "    Illumina Platinum Genomes database : http://www.illumina.com/platinumgenomes/\n",
    "\n",
    "Build : Spark master Google Compute Engine virtual machine\n",
    "\n",
    "Prerequisite : \n",
    "    An upgraded Google Cloud account\n",
    "    A bucket folder name created under the Storage menu.(see above for bucket creation)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Principal Coordinate Analysis counts the number of variants two samples have in common. These counts are then placed into an NxN matrix where N is the number of samples in the variant set. The matrix is centered, scaled, and then the first two principal components are computed for each individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "\n",
    "Create a Spark cluster using Google Cloud Dataproc. This can be done using the Cloud Platform Console or the following gcloud command:\n",
    "\n",
    "    gcloud beta dataproc clusters create cluster-1 --scopes cloud-platform\n",
    "\n",
    "ssh to the master.\n",
    "\n",
    "    gcloud compute ssh cluster-1-m  # -m to get into \n",
    "\n",
    "#### Note : \n",
    "The reference tutorial uses Spark 1.0 and Scala 2.10.4.  Below is the updated code with current version (given above) for both.\n",
    "\n",
    "#### Install sbt.\n",
    "\n",
    "    echo \"deb https://dl.bintray.com/sbt/debian /\" | sudo tee -a /etc/apt/sources.list.d/sbt.list\n",
    "    sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 642AC823\n",
    "    sudo apt-get install apt-transport-https\n",
    "    sudo apt-get update\n",
    "    sudo apt-get install sbt\n",
    "\n",
    "#### Clone the github repository.\n",
    "\n",
    "    sudo apt-get install git\n",
    "    git clone https://github.com/googlegenomics/spark-examples.git\n",
    "\n",
    "#### Compile the Jar.\n",
    "\n",
    "    cd spark-examples\n",
    "    # Edit the build.sbt file. Change version to 2.0 and scalaVersion to 2.11.8. Save the file and exit.\n",
    "    \n",
    "    sbt assembly\n",
    "    cp target/scala-2.11/googlegenomics-spark-examples-assembly-*.jar ~/\n",
    "    cd ~/\n",
    "\n",
    "#### Run the job\n",
    "\n",
    "    spark-submit \\\n",
    "      --class com.google.cloud.genomics.spark.examples.VariantsPcaDriver \\\n",
    "      --conf spark.shuffle.spill=true \\\n",
    "      googlegenomics-spark-examples-assembly-2.0.jar \\\n",
    "      --variant-set-id 3049512673186936334 \\\n",
    "      --references chr17:41196311:41277499 \\\n",
    "      --output-path gs://Bucket-Name/output/platinum-genomes-brca1-pca.tsv\n",
    "\n",
    "#### Following is the sample output :"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "16/10/02 23:50:33 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.5.3-hadoop2\n",
    "Matrix size: 17.\n",
    "Running PCA on 1 datasets.\n",
    "Variantset: 3049512673186936334; Refs: chr17:41196311:41277499\n",
    "Non zero rows in matrix: 17 / 17.\n",
    "16/10/02 23:50:45 INFO com.github.fommil.jni.JniLoader: successfully loaded /tmp/jniloader8836183187137299709netlib-native_system-linux-x86_64.so\n",
    "16/10/02 23:50:45 INFO com.github.fommil.jni.JniLoader: already loaded netlib-native_system-linux-x86_64.so\n",
    "NA12877\t3049512673186936334\t-0.2015509211052402\t0.031330875575183506\n",
    "NA12878\t3049512673186936334\t0.2870307884617765\t-0.23303794838279884\n",
    "NA12879\t3049512673186936334\t-0.20433128691357097\t0.18827344578406946\n",
    "NA12880\t3049512673186936334\t0.28755616274491186\t-0.3759734682420386\n",
    "NA12881\t3049512673186936334\t-0.20477601568774031\t-0.14539360274318863\n",
    "NA12882\t3049512673186936334\t-0.20256569902877403\t0.1635789820298156\n",
    "NA12883\t3049512673186936334\t0.2939974546298187\t-0.5112860866937563\n",
    "NA12884\t3049512673186936334\t-0.2071445311763388\t0.13144211513610662\n",
    "NA12885\t3049512673186936334\t-0.20239419180875257\t0.14764915778737125\n",
    "NA12886\t3049512673186936334\t-0.20547721572161134\t-0.018672933184579663\n",
    "NA12887\t3049512673186936334\t0.2886649313903892\t0.23356411694924764\n",
    "NA12888\t3049512673186936334\t0.29009217805592374\t0.37485796542292854\n",
    "NA12889\t3049512673186936334\t0.2849140767349421\t0.22700001948102072\n",
    "NA12890\t3049512673186936334\t-0.19585791544866357\t-0.22049281871409648\n",
    "NA12891\t3049512673186936334\t-0.20364615783793372\t-0.12065021904360243\n",
    "NA12892\t3049512673186936334\t0.29675115818129233\t0.28888399503684703\n",
    "NA12893\t3049512673186936334\t-0.20126281547042899\t-0.16107359619852724\n",
    "Variants API stats:                                                             \n",
    "-------------------------------\n",
    "# of partitions: 1\n",
    "# of bases requested: 81188\n",
    "# of variants read: 19517\n",
    "# of API requests: 0\n",
    "# of unsuccessful responses: 0\n",
    "# of IO exceptions: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
